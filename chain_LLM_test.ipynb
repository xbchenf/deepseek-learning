{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd56afb-4b0c-4cfa-9570-1d79d28cfe3d",
   "metadata": {},
   "source": [
    "# LLM调用测试（需要先自定义DeepSeek_R1_Distill_Qwen_LLM集成Chain框架  LLM.py）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cd847f-2ee0-432d-9560-c1d7533ced96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing local model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e8693ccae647ea994f8d1d0994236b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1811/4247118100.py:21: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(\"你是谁？\")\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\\n</think>\\n\\n您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LLM import DeepSeek_R1_Distill_Qwen_LLM\n",
    "  \n",
    "llm = DeepSeek_R1_Distill_Qwen_LLM(mode_name_or_path = \"/root/autodl-tmp/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\")\n",
    "\n",
    "response = llm(\"你是谁？\")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71bb5f-cd29-4a25-88b9-ec9b63a75372",
   "metadata": {},
   "source": [
    "## 模型响应结果，正则匹配，拆分测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80e4fd5-5019-4c78-8bf8-387d477fed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "匹配成功！\n",
      "捕获组1: 您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n",
      "\n",
      "捕获组2: \n",
      "\n",
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = '''您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n",
    "</think>\n",
    "\n",
    "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。'''\n",
    "\n",
    "# pattern = re.compile(r'<think>(.*?)</think>(.*)', re.DOTALL)\n",
    "pattern = re.compile(r'(.*?)</think>(.*)', re.DOTALL)\n",
    "match = pattern.search(text)\n",
    "\n",
    "if match:\n",
    "    print(\"匹配成功！\")\n",
    "    print(\"捕获组1:\", match.group(1))  # <think>...</think>之间的内容\n",
    "    print(\"捕获组2:\", match.group(2))  # </think>之后的内容\n",
    "else:\n",
    "    print(\"匹配失败！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355cd044-fe7e-4270-8c15-d3491081c7a9",
   "metadata": {},
   "source": [
    "# 深度思考提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e34538e6-edb0-46a4-a866-ca2e0d42f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 思考过程 --------------------\n",
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n",
      "\n",
      "-------------------- 最终回答 --------------------\n",
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 文本分割函数\n",
    "def split_text(text):\n",
    "    #pattern = re.compile(r'<think>(.*?)</think>(.*)', re.DOTALL) # 定义正则表达式模式\n",
    "    pattern = re.compile(r'(.*?)</think>(.*)', re.DOTALL)\n",
    "    match = pattern.search(text) # 匹配 <think>思考过程</think>回答\n",
    "  \n",
    "    if match: # 如果匹配到思考过程\n",
    "        think_content = match.group(1).strip() # 获取思考过程\n",
    "        answer_content = match.group(2).strip() # 获取回答\n",
    "    else:\n",
    "        think_content = \"\" # 如果没有匹配到思考过程，则设置为空字符串\n",
    "        answer_content = text.strip() # 直接返回回答\n",
    "  \n",
    "    return think_content, answer_content\n",
    "\n",
    "response = llm(\"你是谁？\")\n",
    "\n",
    "think, answer = split_text(response)\n",
    "\n",
    "print(f\"{'-'*20} 思考过程 {'-'*20}\")\n",
    "print(think)\n",
    "print(f\"\\n{'-'*20} 最终回答 {'-'*20}\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d6f40-2293-439f-9384-e66a6616351d",
   "metadata": {},
   "source": [
    "# 深度思考提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a378cf-1a3d-4b6d-abe2-fca0cddbc969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 思考过程 --------------------\n",
      "首先，我有6个苹果。\n",
      "\n",
      "我吃掉了1个苹果，剩下5个。\n",
      "\n",
      "然后，我送了你2个苹果，剩下3个。\n",
      "\n",
      "接着，苹果掉了3个，所以剩下的苹果数量减少了3个。\n",
      "\n",
      "最后，我剩下0个苹果。\n",
      "\n",
      "-------------------- 最终回答 --------------------\n",
      "**解答：**\n",
      "\n",
      "1. **初始苹果数量：**\n",
      "   \\[\n",
      "   6 \\text{个}\n",
      "   \\]\n",
      "\n",
      "2. **吃掉1个苹果：**\n",
      "   \\[\n",
      "   6 - 1 = 5 \\text{个}\n",
      "   \\]\n",
      "\n",
      "3. **送给对方2个苹果：**\n",
      "   \\[\n",
      "   5 - 2 = 3 \\text{个}\n",
      "   \\]\n",
      "\n",
      "4. **苹果掉落地掉3个：**\n",
      "   \\[\n",
      "   3 - 3 = 0 \\text{个}\n",
      "   \\]\n",
      "\n",
      "**最终剩下的苹果数量：**\n",
      "\\[\n",
      "\\boxed{0}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "response = llm(\"我有6个苹果，吃了1个，送给了你2个，掉3个还剩多少个？\")\n",
    "think, answer = split_text(response)\n",
    "\n",
    "print(f\"{'-'*20} 思考过程 {'-'*20}\")\n",
    "print(think)\n",
    "print(f\"\\n{'-'*20} 最终回答 {'-'*20}\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d67a9-668f-4c36-8573-c7a9d8feea9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
